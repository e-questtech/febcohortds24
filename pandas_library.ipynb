{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas Library\n",
    "\n",
    "Pandas is a Python library.\n",
    "\n",
    "Pandas is used to analyze data.\n",
    "#### What is Pandas?\n",
    "Pandas is a Python library used for working with data sets.\n",
    "\n",
    "It has functions for analyzing, cleaning, exploring, and manipulating data.\n",
    "\n",
    "The name \"Pandas\" has a reference to both \"Panel Data\", and \"Python Data Analysis\" and was created by Wes McKinney in 2008.\n",
    "\n",
    "#### Why Use Pandas?\n",
    "Pandas allows us to analyze big data and make conclusions based on statistical theories.\n",
    "\n",
    "Pandas can clean messy data sets, and make them readable and relevant.\n",
    "\n",
    "Relevant data is very important in data science."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Installation of Pandas\n",
    "#pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Once Pandas is installed, import it in your applications by adding the import keyword:\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is a Pandas Series?\n",
    "A Pandas Series is like a column in a table.\n",
    "\n",
    "It is a one-dimensional array holding data of any type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1\n",
      "1    7\n",
      "2    2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Create a simple Pandas Series from a list:\n",
    "\n",
    "a = [1, 7, 2]\n",
    "\n",
    "myvar = pd.Series(a)\n",
    "\n",
    "print(myvar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create Labels\n",
    "#With the index argument, you can name your own labels.\n",
    "#Create your own labels:\n",
    "\n",
    "a = [1, 7, 2]\n",
    "\n",
    "myvar = pd.Series(a, index = [\"x\", \"y\", \"z\"])\n",
    "\n",
    "print(myvar)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrames\n",
    "Data sets in Pandas are usually multi-dimensional tables, called DataFrames.\n",
    "\n",
    "Series is like a column, a DataFrame is the whole table.\n",
    "A Pandas DataFrame is a 2 dimensional data structure, like a 2 dimensional array, or a table with rows and columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a simple Pandas DataFrame:\n",
    "\n",
    "data = {\n",
    "  \"calories\": [420, 380, 390],\n",
    "  \"duration\": [50, 40, 45]\n",
    "}\n",
    "\n",
    "#load data into a DataFrame object:\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Locate Row\n",
    "As you can see from the result above, the DataFrame is like a table with rows and columns.\n",
    "\n",
    "Pandas use the loc attribute to return one or more specified row(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Return row 0:\n",
    "\n",
    "#refer to the row index:\n",
    "df.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Return row 0 and 1:\n",
    "\n",
    "#use a list of indexes:\n",
    "df.loc[[0, 1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Named Indexes\n",
    "#With the index argument, you can name your own indexes.\n",
    "#Add a list of names to give each row a name:\n",
    "\n",
    "data = {\n",
    "  \"calories\": [420, 380, 390],\n",
    "  \"duration\": [50, 40, 45]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data, index = [\"day1\", \"day2\", \"day3\"])\n",
    "\n",
    "df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Locate Named Indexes\n",
    "#Use the named index in the loc attribute to return the specified row(s).\n",
    "#Return \"day2\":\n",
    "\n",
    "#refer to the named index:\n",
    "print(df.loc[\"day2\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Files Into a DataFrame\n",
    "If your data sets are stored in a file, Pandas can load them into a DataFrame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       transaction_id  product_id  customer_id transaction_date  online_order  \\\n",
      "0                   1           2         2950       2017-02-25           0.0   \n",
      "1                   2           3         3120       2017-05-21           1.0   \n",
      "2                   3          37          402       2017-10-16           0.0   \n",
      "3                   4          88         3135       2017-08-31           0.0   \n",
      "4                   5          78          787       2017-10-01           1.0   \n",
      "...               ...         ...          ...              ...           ...   \n",
      "19995           19996          51         1018       2017-06-24           1.0   \n",
      "19996           19997          41          127       2017-11-09           1.0   \n",
      "19997           19998          87         2284       2017-04-14           1.0   \n",
      "19998           19999           6         2764       2017-07-03           0.0   \n",
      "19999           20000          11         1144       2017-09-22           1.0   \n",
      "\n",
      "      order_status           brand product_line product_class product_size  \\\n",
      "0         Approved           Solex     Standard        medium       medium   \n",
      "1         Approved   Trek Bicycles     Standard        medium        large   \n",
      "2         Approved      OHM Cycles     Standard           low       medium   \n",
      "3         Approved  Norco Bicycles     Standard        medium       medium   \n",
      "4         Approved  Giant Bicycles     Standard        medium        large   \n",
      "...            ...             ...          ...           ...          ...   \n",
      "19995     Approved      OHM Cycles     Standard          high       medium   \n",
      "19996     Approved           Solex         Road        medium       medium   \n",
      "19997     Approved      OHM Cycles     Standard        medium       medium   \n",
      "19998     Approved      OHM Cycles     Standard          high       medium   \n",
      "19999     Approved   Trek Bicycles     Standard        medium        small   \n",
      "\n",
      "       list_price  standard_cost  product_first_sold_date  \n",
      "0           71.49          53.62                  41245.0  \n",
      "1         2091.47         388.92                  41701.0  \n",
      "2         1793.43         248.82                  36361.0  \n",
      "3         1198.46         381.10                  36145.0  \n",
      "4         1765.30         709.48                  42226.0  \n",
      "...           ...            ...                      ...  \n",
      "19995     2005.66        1203.40                  37823.0  \n",
      "19996      416.98         312.74                  35560.0  \n",
      "19997     1636.90          44.71                  40410.0  \n",
      "19998      227.88         136.73                  38216.0  \n",
      "19999     1775.81        1580.47                  36334.0  \n",
      "\n",
      "[20000 rows x 13 columns]\n"
     ]
    }
   ],
   "source": [
    "#Load a comma separated file (CSV file) into a DataFrame:\n",
    "\n",
    "df = pd.read_excel('C:\\\\Users\\\\Udser21\\\\Downloads\\\\transaction.xlsx')\n",
    "\n",
    "df "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read CSV Files\n",
    "A simple way to store big data sets is to use CSV files (comma separated files).\n",
    "\n",
    "CSV files contains plain text and is a well know format that can be read by everyone including Pandas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the CSV into a DataFrame:\n",
    "\n",
    "df = pd.read_csv('C:\\\\Users\\\\User21\\\\Downloads\\\\Sales_2019\\\\Sales_April_2019.csv')\n",
    "\n",
    "print(df.to_string()) \n",
    "#use to_string() to print the entire DataFrame.\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n"
     ]
    }
   ],
   "source": [
    "#Check the number of maximum returned rows:\n",
    "pd.options.display.max_rows "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas - Analyzing DataFrames\n",
    "\n",
    "#### Viewing the Data\n",
    "One of the most used method for getting a quick overview of the DataFrame, is the head() method.\n",
    "\n",
    "The head() method returns the headers and a specified number of rows, starting from the top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   transaction_id  product_id  customer_id transaction_date  online_order  \\\n",
      "0               1           2         2950       2017-02-25           0.0   \n",
      "1               2           3         3120       2017-05-21           1.0   \n",
      "2               3          37          402       2017-10-16           0.0   \n",
      "3               4          88         3135       2017-08-31           0.0   \n",
      "4               5          78          787       2017-10-01           1.0   \n",
      "5               6          25         2339       2017-03-08           1.0   \n",
      "6               7          22         1542       2017-04-21           1.0   \n",
      "7               8          15         2459       2017-07-15           0.0   \n",
      "8               9          67         1305       2017-08-10           0.0   \n",
      "9              10          12         3262       2017-08-30           1.0   \n",
      "\n",
      "  order_status           brand product_line product_class product_size  \\\n",
      "0     Approved           Solex     Standard        medium       medium   \n",
      "1     Approved   Trek Bicycles     Standard        medium        large   \n",
      "2     Approved      OHM Cycles     Standard           low       medium   \n",
      "3     Approved  Norco Bicycles     Standard        medium       medium   \n",
      "4     Approved  Giant Bicycles     Standard        medium        large   \n",
      "5     Approved  Giant Bicycles         Road        medium       medium   \n",
      "6     Approved        WeareA2B     Standard        medium       medium   \n",
      "7     Approved        WeareA2B     Standard        medium       medium   \n",
      "8     Approved           Solex     Standard        medium        large   \n",
      "9     Approved        WeareA2B     Standard        medium       medium   \n",
      "\n",
      "   list_price  standard_cost  product_first_sold_date  \n",
      "0       71.49          53.62                  41245.0  \n",
      "1     2091.47         388.92                  41701.0  \n",
      "2     1793.43         248.82                  36361.0  \n",
      "3     1198.46         381.10                  36145.0  \n",
      "4     1765.30         709.48                  42226.0  \n",
      "5     1538.99         829.65                  39031.0  \n",
      "6       60.34          45.26                  34165.0  \n",
      "7     1292.84          13.44                  39915.0  \n",
      "8     1071.23         380.74                  33455.0  \n",
      "9     1231.15         161.60                  38216.0  \n"
     ]
    }
   ],
   "source": [
    "#Get a quick overview by printing the first 10 rows of the DataFrame:\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       transaction_id  product_id  customer_id transaction_date  online_order  \\\n",
      "19995           19996          51         1018       2017-06-24           1.0   \n",
      "19996           19997          41          127       2017-11-09           1.0   \n",
      "19997           19998          87         2284       2017-04-14           1.0   \n",
      "19998           19999           6         2764       2017-07-03           0.0   \n",
      "19999           20000          11         1144       2017-09-22           1.0   \n",
      "\n",
      "      order_status          brand product_line product_class product_size  \\\n",
      "19995     Approved     OHM Cycles     Standard          high       medium   \n",
      "19996     Approved          Solex         Road        medium       medium   \n",
      "19997     Approved     OHM Cycles     Standard        medium       medium   \n",
      "19998     Approved     OHM Cycles     Standard          high       medium   \n",
      "19999     Approved  Trek Bicycles     Standard        medium        small   \n",
      "\n",
      "       list_price  standard_cost  product_first_sold_date  \n",
      "19995     2005.66        1203.40                  37823.0  \n",
      "19996      416.98         312.74                  35560.0  \n",
      "19997     1636.90          44.71                  40410.0  \n",
      "19998      227.88         136.73                  38216.0  \n",
      "19999     1775.81        1580.47                  36334.0  \n"
     ]
    }
   ],
   "source": [
    "#There is also a tail() method for viewing the last rows of the DataFrame.\n",
    "#The tail() method returns the headers and a specified number of rows, starting from the bottom.\n",
    "\n",
    "#Print the last 5 rows of the DataFrame:\n",
    "\n",
    "df.tail() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Info About the Data\n",
    "The DataFrames object has a method called info(), that gives you more information about the data set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20000 entries, 0 to 19999\n",
      "Data columns (total 13 columns):\n",
      " #   Column                   Non-Null Count  Dtype         \n",
      "---  ------                   --------------  -----         \n",
      " 0   transaction_id           20000 non-null  int64         \n",
      " 1   product_id               20000 non-null  int64         \n",
      " 2   customer_id              20000 non-null  int64         \n",
      " 3   transaction_date         20000 non-null  datetime64[ns]\n",
      " 4   online_order             19640 non-null  float64       \n",
      " 5   order_status             20000 non-null  object        \n",
      " 6   brand                    19803 non-null  object        \n",
      " 7   product_line             19803 non-null  object        \n",
      " 8   product_class            19803 non-null  object        \n",
      " 9   product_size             19803 non-null  object        \n",
      " 10  list_price               20000 non-null  float64       \n",
      " 11  standard_cost            19803 non-null  float64       \n",
      " 12  product_first_sold_date  19803 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(4), int64(3), object(5)\n",
      "memory usage: 2.0+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#Print information about the data:\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Null Values\n",
    "The isnull() method also tells us how many Non-Null values there are present in each column.\n",
    "\n",
    "Empty values, or Null values, can be bad when analyzing data, and you should consider removing rows with empty values. This is a step towards what is called cleaning data, and you will learn more about that in the next chapters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transaction_id               0\n",
       "product_id                   0\n",
       "customer_id                  0\n",
       "transaction_date             0\n",
       "online_order               360\n",
       "order_status                 0\n",
       "brand                        0\n",
       "product_line                 0\n",
       "product_class              197\n",
       "product_size               197\n",
       "list_price                   0\n",
       "standard_cost              197\n",
       "product_first_sold_date    197\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Solex', 'Trek Bicycles', 'OHM Cycles', 'Norco Bicycles',\n",
       "       'Giant Bicycles', 'WeareA2B', 'nan'], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In pandas, the astype() function is used to change the data type to a desired data type\n",
    "df.astype({\"order_status\":str}) \n",
    "df = df.astype({\"brand\":str, \"product_line\":str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20000 entries, 0 to 19999\n",
      "Data columns (total 13 columns):\n",
      " #   Column                   Non-Null Count  Dtype         \n",
      "---  ------                   --------------  -----         \n",
      " 0   transaction_id           20000 non-null  int64         \n",
      " 1   product_id               20000 non-null  int64         \n",
      " 2   customer_id              20000 non-null  int64         \n",
      " 3   transaction_date         20000 non-null  datetime64[ns]\n",
      " 4   online_order             19640 non-null  float64       \n",
      " 5   order_status             20000 non-null  object        \n",
      " 6   brand                    20000 non-null  object        \n",
      " 7   product_line             20000 non-null  object        \n",
      " 8   product_class            19803 non-null  object        \n",
      " 9   product_size             19803 non-null  object        \n",
      " 10  list_price               20000 non-null  float64       \n",
      " 11  standard_cost            19803 non-null  float64       \n",
      " 12  product_first_sold_date  19803 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(4), int64(3), object(5)\n",
      "memory usage: 2.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas - Cleaning Data\n",
    "Data cleaning means fixing bad data in your data set.\n",
    "\n",
    "Bad data could be:\n",
    "\n",
    "* Empty cells\n",
    "* Data in wrong format\n",
    "* Wrong data\n",
    "* Duplicates\n",
    "In this tutorial you will learn how to deal with all of them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Empty Cells\n",
    "Empty cells can potentially give you a wrong result when you analyze data.\n",
    "\n",
    "Remove Rows\n",
    "One way to deal with empty cells is to remove rows that contain empty cells.\n",
    "\n",
    "This is usually OK, since data sets can be very big, and removing a few rows will not have a big impact on the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transaction_id               0\n",
       "product_id                   0\n",
       "customer_id                  0\n",
       "transaction_date             0\n",
       "online_order               360\n",
       "order_status                 0\n",
       "brand                        0\n",
       "product_line                 0\n",
       "product_class              197\n",
       "product_size               197\n",
       "list_price                   0\n",
       "standard_cost              197\n",
       "product_first_sold_date    197\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Return a new Data Frame with no empty cells:\n",
    "\n",
    "\n",
    "new_df = df.dropna()\n",
    "\n",
    "df\n",
    "#By default, the dropna() method returns a new DataFrame, and will not change the original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove all rows with NULL values:\n",
    "#If you want to change the original DataFrame, use the inplace = True argument:\n",
    "\n",
    "df.dropna(inplace = True)\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace Empty Values\n",
    "Another way of dealing with empty cells is to insert a new value instead.\n",
    "\n",
    "This way you do not have to delete entire rows just because of some empty cells.\n",
    "\n",
    "The fillna() method allows us to replace empty cells with a value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Udser21\\AppData\\Local\\Temp\\ipykernel_7224\\1366402019.py:1: FutureWarning: Inferring datetime64[ns] from data containing strings is deprecated and will be removed in a future version. To retain the old behavior explicitly pass Series(data, dtype=datetime64[ns])\n",
      "  df2 = pd.read_excel('C:\\\\Users\\\\Udser21\\\\Downloads\\\\New_customer_list.xlsx')\n"
     ]
    }
   ],
   "source": [
    "df2 = pd.read_excel('C:\\\\Users\\\\Udser21\\\\Downloads\\\\New_customer_list.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>gender</th>\n",
       "      <th>past_3_years_bike_related_purchases</th>\n",
       "      <th>DOB</th>\n",
       "      <th>job_title</th>\n",
       "      <th>job_industry_category</th>\n",
       "      <th>wealth_segment</th>\n",
       "      <th>deceased_indicator</th>\n",
       "      <th>owns_car</th>\n",
       "      <th>...</th>\n",
       "      <th>state</th>\n",
       "      <th>country</th>\n",
       "      <th>property_valuation</th>\n",
       "      <th>Unnamed: 16</th>\n",
       "      <th>Unnamed: 17</th>\n",
       "      <th>Unnamed: 18</th>\n",
       "      <th>Unnamed: 19</th>\n",
       "      <th>Unnamed: 20</th>\n",
       "      <th>Rank</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chickie</td>\n",
       "      <td>Brister</td>\n",
       "      <td>Male</td>\n",
       "      <td>86</td>\n",
       "      <td>1957-07-12</td>\n",
       "      <td>General Manager</td>\n",
       "      <td>Manufacturing</td>\n",
       "      <td>Mass Customer</td>\n",
       "      <td>N</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>QLD</td>\n",
       "      <td>Australia</td>\n",
       "      <td>6</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.531250</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.718750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Morly</td>\n",
       "      <td>Genery</td>\n",
       "      <td>Male</td>\n",
       "      <td>69</td>\n",
       "      <td>1970-03-22</td>\n",
       "      <td>Structural Engineer</td>\n",
       "      <td>Property</td>\n",
       "      <td>Mass Customer</td>\n",
       "      <td>N</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>NSW</td>\n",
       "      <td>Australia</td>\n",
       "      <td>11</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.7900</td>\n",
       "      <td>0.9875</td>\n",
       "      <td>0.839375</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.718750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ardelis</td>\n",
       "      <td>Forrester</td>\n",
       "      <td>Female</td>\n",
       "      <td>10</td>\n",
       "      <td>1974-08-28</td>\n",
       "      <td>Senior Cost Accountant</td>\n",
       "      <td>Financial Services</td>\n",
       "      <td>Affluent Customer</td>\n",
       "      <td>N</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>VIC</td>\n",
       "      <td>Australia</td>\n",
       "      <td>5</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.5300</td>\n",
       "      <td>0.5300</td>\n",
       "      <td>0.530000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.718750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lucine</td>\n",
       "      <td>Stutt</td>\n",
       "      <td>Female</td>\n",
       "      <td>64</td>\n",
       "      <td>1979-01-28</td>\n",
       "      <td>Account Representative III</td>\n",
       "      <td>Manufacturing</td>\n",
       "      <td>Affluent Customer</td>\n",
       "      <td>N</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>QLD</td>\n",
       "      <td>Australia</td>\n",
       "      <td>1</td>\n",
       "      <td>1.03</td>\n",
       "      <td>1.2875</td>\n",
       "      <td>1.2875</td>\n",
       "      <td>1.287500</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1.703125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Melinda</td>\n",
       "      <td>Hadlee</td>\n",
       "      <td>Female</td>\n",
       "      <td>34</td>\n",
       "      <td>1965-09-21</td>\n",
       "      <td>Financial Analyst</td>\n",
       "      <td>Financial Services</td>\n",
       "      <td>Affluent Customer</td>\n",
       "      <td>N</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>NSW</td>\n",
       "      <td>Australia</td>\n",
       "      <td>9</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.5800</td>\n",
       "      <td>0.7250</td>\n",
       "      <td>0.725000</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1.703125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Ferdinand</td>\n",
       "      <td>Romanetti</td>\n",
       "      <td>Male</td>\n",
       "      <td>60</td>\n",
       "      <td>1959-10-07</td>\n",
       "      <td>Paralegal</td>\n",
       "      <td>Financial Services</td>\n",
       "      <td>Affluent Customer</td>\n",
       "      <td>N</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>NSW</td>\n",
       "      <td>Australia</td>\n",
       "      <td>7</td>\n",
       "      <td>1.09</td>\n",
       "      <td>1.0900</td>\n",
       "      <td>1.0900</td>\n",
       "      <td>1.090000</td>\n",
       "      <td>996</td>\n",
       "      <td>996</td>\n",
       "      <td>0.374000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>Burk</td>\n",
       "      <td>Wortley</td>\n",
       "      <td>Male</td>\n",
       "      <td>22</td>\n",
       "      <td>2001-10-17</td>\n",
       "      <td>Senior Sales Associate</td>\n",
       "      <td>Health</td>\n",
       "      <td>Mass Customer</td>\n",
       "      <td>N</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>NSW</td>\n",
       "      <td>Australia</td>\n",
       "      <td>10</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.5200</td>\n",
       "      <td>0.6500</td>\n",
       "      <td>0.552500</td>\n",
       "      <td>997</td>\n",
       "      <td>997</td>\n",
       "      <td>0.357000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Melloney</td>\n",
       "      <td>Temby</td>\n",
       "      <td>Female</td>\n",
       "      <td>17</td>\n",
       "      <td>1954-10-05</td>\n",
       "      <td>Budget/Accounting Analyst IV</td>\n",
       "      <td>Financial Services</td>\n",
       "      <td>Affluent Customer</td>\n",
       "      <td>N</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>QLD</td>\n",
       "      <td>Australia</td>\n",
       "      <td>2</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.8750</td>\n",
       "      <td>0.8750</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>997</td>\n",
       "      <td>997</td>\n",
       "      <td>0.357000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>Dickie</td>\n",
       "      <td>Cubbini</td>\n",
       "      <td>Male</td>\n",
       "      <td>30</td>\n",
       "      <td>1952-12-17</td>\n",
       "      <td>Financial Advisor</td>\n",
       "      <td>Financial Services</td>\n",
       "      <td>Mass Customer</td>\n",
       "      <td>N</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>QLD</td>\n",
       "      <td>Australia</td>\n",
       "      <td>2</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.584375</td>\n",
       "      <td>997</td>\n",
       "      <td>997</td>\n",
       "      <td>0.357000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>Sylas</td>\n",
       "      <td>Duffill</td>\n",
       "      <td>Male</td>\n",
       "      <td>56</td>\n",
       "      <td>1955-10-02</td>\n",
       "      <td>Staff Accountant IV</td>\n",
       "      <td>Property</td>\n",
       "      <td>Mass Customer</td>\n",
       "      <td>N</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>NSW</td>\n",
       "      <td>Australia</td>\n",
       "      <td>9</td>\n",
       "      <td>1.04</td>\n",
       "      <td>1.3000</td>\n",
       "      <td>1.6250</td>\n",
       "      <td>1.381250</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.340000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    first_name  last_name  gender  past_3_years_bike_related_purchases  \\\n",
       "0      Chickie    Brister    Male                                   86   \n",
       "1        Morly     Genery    Male                                   69   \n",
       "2      Ardelis  Forrester  Female                                   10   \n",
       "3       Lucine      Stutt  Female                                   64   \n",
       "4      Melinda     Hadlee  Female                                   34   \n",
       "..         ...        ...     ...                                  ...   \n",
       "995  Ferdinand  Romanetti    Male                                   60   \n",
       "996       Burk    Wortley    Male                                   22   \n",
       "997   Melloney      Temby  Female                                   17   \n",
       "998     Dickie    Cubbini    Male                                   30   \n",
       "999      Sylas    Duffill    Male                                   56   \n",
       "\n",
       "           DOB                     job_title job_industry_category  \\\n",
       "0   1957-07-12               General Manager         Manufacturing   \n",
       "1   1970-03-22           Structural Engineer              Property   \n",
       "2   1974-08-28        Senior Cost Accountant    Financial Services   \n",
       "3   1979-01-28    Account Representative III         Manufacturing   \n",
       "4   1965-09-21             Financial Analyst    Financial Services   \n",
       "..         ...                           ...                   ...   \n",
       "995 1959-10-07                     Paralegal    Financial Services   \n",
       "996 2001-10-17        Senior Sales Associate                Health   \n",
       "997 1954-10-05  Budget/Accounting Analyst IV    Financial Services   \n",
       "998 1952-12-17             Financial Advisor    Financial Services   \n",
       "999 1955-10-02           Staff Accountant IV              Property   \n",
       "\n",
       "        wealth_segment deceased_indicator owns_car  ...  state    country  \\\n",
       "0        Mass Customer                  N      Yes  ...    QLD  Australia   \n",
       "1        Mass Customer                  N       No  ...    NSW  Australia   \n",
       "2    Affluent Customer                  N       No  ...    VIC  Australia   \n",
       "3    Affluent Customer                  N      Yes  ...    QLD  Australia   \n",
       "4    Affluent Customer                  N       No  ...    NSW  Australia   \n",
       "..                 ...                ...      ...  ...    ...        ...   \n",
       "995  Affluent Customer                  N       No  ...    NSW  Australia   \n",
       "996      Mass Customer                  N       No  ...    NSW  Australia   \n",
       "997  Affluent Customer                  N      Yes  ...    QLD  Australia   \n",
       "998      Mass Customer                  N      Yes  ...    QLD  Australia   \n",
       "999      Mass Customer                  N      Yes  ...    NSW  Australia   \n",
       "\n",
       "     property_valuation Unnamed: 16 Unnamed: 17  Unnamed: 18  Unnamed: 19  \\\n",
       "0                     6        0.40      0.5000       0.6250     0.531250   \n",
       "1                    11        0.79      0.7900       0.9875     0.839375   \n",
       "2                     5        0.53      0.5300       0.5300     0.530000   \n",
       "3                     1        1.03      1.2875       1.2875     1.287500   \n",
       "4                     9        0.58      0.5800       0.7250     0.725000   \n",
       "..                  ...         ...         ...          ...          ...   \n",
       "995                   7        1.09      1.0900       1.0900     1.090000   \n",
       "996                  10        0.52      0.5200       0.6500     0.552500   \n",
       "997                   2        0.70      0.8750       0.8750     0.875000   \n",
       "998                   2        0.55      0.6875       0.6875     0.584375   \n",
       "999                   9        1.04      1.3000       1.6250     1.381250   \n",
       "\n",
       "     Unnamed: 20  Rank     Value  \n",
       "0              1     1  1.718750  \n",
       "1              1     1  1.718750  \n",
       "2              1     1  1.718750  \n",
       "3              4     4  1.703125  \n",
       "4              4     4  1.703125  \n",
       "..           ...   ...       ...  \n",
       "995          996   996  0.374000  \n",
       "996          997   997  0.357000  \n",
       "997          997   997  0.357000  \n",
       "998          997   997  0.357000  \n",
       "999         1000  1000  0.340000  \n",
       "\n",
       "[1000 rows x 23 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "first_name                               0\n",
       "last_name                               29\n",
       "gender                                   0\n",
       "past_3_years_bike_related_purchases      0\n",
       "DOB                                     17\n",
       "job_title                              106\n",
       "job_industry_category                  165\n",
       "wealth_segment                           0\n",
       "deceased_indicator                       0\n",
       "owns_car                                 0\n",
       "tenure                                   0\n",
       "address                                  0\n",
       "postcode                                 0\n",
       "state                                    0\n",
       "country                                  0\n",
       "property_valuation                       0\n",
       "Unnamed: 16                              0\n",
       "Unnamed: 17                              0\n",
       "Unnamed: 18                              0\n",
       "Unnamed: 19                              0\n",
       "Unnamed: 20                              0\n",
       "Rank                                     0\n",
       "Value                                    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace NULL values with the number 130:\n",
    "df.fillna(130, inplace = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Replace Only For Specified Columns\n",
    "The example above replaces all empty cells in the whole Data Frame.\n",
    "\n",
    "To only replace empty values for one column, specify the column name for the DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace specified column\n",
    "df[\"online_order\"].fillna(130, inplace = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Replace Using Mean, Median, or Mode\n",
    "A common way to replace empty cells, is to calculate the mean, median or mode value of the column.\n",
    "\n",
    "Pandas uses the mean() median() and mode() methods to calculate the respective values for a specified column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the MEAN, and replace any empty values with it:\n",
    "\n",
    "x = df[\"Calories\"].mean()\n",
    "\n",
    "df[\"Calories\"].fillna(x, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the MEDIAN, and replace any empty values with it:\n",
    "\n",
    "x = df[\"Calories\"].median()\n",
    "\n",
    "df[\"Calories\"].fillna(x, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the MODE, and replace any empty values with it:\n",
    "\n",
    "x = df[\"Calories\"].mode()[0]\n",
    "\n",
    "df[\"Calories\"].fillna(x, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data of Wrong Format\n",
    "Cells with data of wrong format can make it difficult, or even impossible, to analyze data.\n",
    "\n",
    "To fix it, you have two options: remove the rows, or convert all cells in the columns into the same format.\n",
    "Pandas has the to_datetime() method used to coreect incorrect date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  1., nan])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The unique() function is used to obtain the unique elements in the dataframe column\n",
    "df[\"online_order\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert to date:\n",
    "\n",
    "df['transaction_date '] = pd.to_datetime(df['transaction_date '])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To identify the row where a wrong data is contained. two methods can be applied"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrong Data\n",
    "\"Wrong data\" does not have to be \"empty cells\" or \"wrong format\", it can just be wrong, like if someone registered \"199\" instead of \"1.99\".\n",
    "\n",
    "Sometimes you can spot wrong data by looking at the data set, because you have an expectation of what it should be.\n",
    "\n",
    "If you take a look at our data set, you can see that in row 7, the duration is 450, but for all the other rows the duration is between 30 and 60.\n",
    "\n",
    "It doesn't have to be wrong, but taking in consideration that this is the data set of someone's workout sessions, we conclude with the fact that this person did not work out in 450 minutes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing Values\n",
    "#One way to fix wrong values is to replace them with something else.\n",
    "\n",
    "df.loc[7, 'Duration'] = 45"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing Rows\n",
    "Another way of handling wrong data is to remove the rows that contains wrong data.\n",
    "\n",
    "This way you do not have to find out what to replace them with, and there is a good chance you do not need them to do your analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Delete rows where \"Duration\" is higher than 120:\n",
    "\n",
    "for x in df.index:\n",
    "  if df.loc[x, \"Duration\"] > 120:\n",
    "    df.drop(x, inplace = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discovering Duplicates\n",
    "Duplicate rows are rows that have been registered more than one time.\n",
    "To discover duplicates, we can use the duplicated() method.\n",
    "The duplicated() method returns a Boolean values for each row:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        False\n",
      "1        False\n",
      "2        False\n",
      "3        False\n",
      "4        False\n",
      "         ...  \n",
      "19995    False\n",
      "19996    False\n",
      "19997    False\n",
      "19998    False\n",
      "19999    False\n",
      "Length: 20000, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "#Returns True for every row that is a duplicate, othwerwise False:\n",
    "\n",
    "df.duplicated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to view the duplicated data\n",
    "df[df.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To remove duplicates, use the drop_duplicates() method.\n",
    "df.drop_duplicates(inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding Relationships\n",
    "A great aspect of the Pandas module is the corr() method.\n",
    "The corr() method calculates the relationship between each column in your data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Show the relationship between the columns:\n",
    "\n",
    "df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### What is a good correlation? \n",
    "It depends on the use, but I think it is safe to say you have to have at least 0.6 (or -0.6) to call it a good correlation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The groupby() function is used for grouping and aggregating data in a dataframe. It allows you to split a Dataframe into groups based on one or more columns and then performing various operations on these groups such as aggregation, transformation, or filtering. \n",
    "the syntax: grouped = df.groupby(by)\n",
    "df: the dataframe you want to group\n",
    "by: specifies the criteria for grouping, which can be a column name, a list of column names, a series, or a function\n",
    "\n",
    "Once you've created a object, functions such as sum(), mean(), count(), agg(), can be applied to calculate statistics for ech groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby([\"product_id \"])[\"product_id \"].count().sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting\n",
    "Pandas uses the plot() method to create diagrams.\n",
    "\n",
    "We can use Pyplot, a submodule of the Matplotlib library to visualize the diagram on the screen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import pyplot from Matplotlib and visualize our DataFrame:\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv('data.csv')\n",
    "\n",
    "df.plot()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify the kind of plot you want with the \"kind\" argument:\n",
    "Example\n",
    "kind = 'scatter'\n",
    "kind = 'bar'\n",
    "kind = 'hist'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
